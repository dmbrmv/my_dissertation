# Quick Start Guide: GR4J Calibration Improvements

## ðŸŽ¯ What Changed?

Three new files implement research-backed improvements to your GR4J + CemaNeige calibration:

1. **`src/utils/metrics_enhanced.py`** - New metrics for better low/high flow coverage
2. **`src/models/gr4j/gr4j_optuna_improved.py`** - Enhanced optimization with warm-up
3. **`docs/gr4j_calibration_improvement_plan.md`** - Full technical documentation

## ðŸš€ Quick Test (5 minutes)

### Option 1: Test on a Single Gauge

```python
from pathlib import Path
import xarray as xr
import geopandas as gpd
from src.models.gr4j.gr4j_optuna_improved import run_optimization
from src.models.gr4j.pareto import select_best_trial_weighted, analyze_pareto_front
from src.models.gr4j.pet import pet_oudin
from src.readers.geom_reader import load_geodata

# Load one gauge for testing
gauge_id = "10007"  # Pick any gauge you have
_, gauges = load_geodata(folder_depth="../")
latitude = float(gauges.loc[gauge_id, "geometry"].y)

# Load data
with xr.open_dataset(f"../data/nc_all_q/{gauge_id}.nc") as ds:
    data = ds.to_dataframe()
    data["t_mean_e5l"] = (data["t_max_e5l"] + data["t_min_e5l"]) / 2

# Select one dataset
dataset = "e5l"
gr4j_data = data.loc[
    "2005":"2020",  # Extended to include warm-up period
    ["q_mm_day", "t_min_e5l", "t_mean_e5l", "t_max_e5l", f"prcp_{dataset}"],
].copy()
gr4j_data.rename(columns={f"prcp_{dataset}": "prcp", "t_mean_e5l": "t_mean"}, inplace=True)

# Add day_of_year and PET
gr4j_data["day_of_year"] = gr4j_data.index.dayofyear
t_mean_list = gr4j_data["t_mean"].tolist()
day_of_year_list = gr4j_data["day_of_year"].tolist()
gr4j_data["pet_mm_day"] = pet_oudin(t_mean_list, day_of_year_list, latitude)

# Run improved optimization (note: 2008 calibration start, but warm-up from 2005)
study = run_optimization(
    gr4j_data,
    calibration_period=("2008-01-01", "2018-12-31"),
    study_name=f"test_improved_{gauge_id}_{dataset}",
    n_trials=100,  # Quick test
    timeout=300,
    verbose=True,
    warmup_years=2,
    use_detailed=False  # Start with simpler 4-objective approach
)

# Analyze results
pareto_df = analyze_pareto_front(study.best_trials)
print(f"\nðŸ“Š Found {len(study.best_trials)} Pareto-optimal solutions")
print("\nTop 5 by KGE:")
print(pareto_df[["KGE", "low_flow_composite", "high_flow_composite", "PBIAS"]].head())

# Select best parameter set
weights = {
    "KGE": 0.25,
    "low_flow": 0.35,    # Emphasizing low flows
    "high_flow": 0.30,
    "PBIAS": 0.10,
}
best_trial = select_best_trial_weighted(study.best_trials, weights, method="weighted_sum")
print(f"\nâœ… Best parameters (weighted selection):")
for param, value in best_trial.params.items():
    print(f"  {param}: {value:.3f}")
```

### Option 2: Compare Old vs New Approach

```python
# Run BOTH approaches on same gauge
from src.models.gr4j.gr4j_optuna import run_optimization as run_old
from src.models.gr4j.gr4j_optuna_improved import run_optimization as run_new

# Old approach (no warm-up, wider bounds, 5 objectives)
study_old = run_old(
    gr4j_data,
    calibration_period=("2008-01-01", "2018-12-31"),
    study_name="old_approach",
    n_trials=100,
    timeout=300
)

# New approach (2-year warm-up, corrected bounds, 4 composite objectives)
study_new = run_new(
    gr4j_data,
    calibration_period=("2008-01-01", "2018-12-31"),
    study_name="new_approach",
    n_trials=100,
    timeout=300,
    warmup_years=2
)

# Compare Pareto fronts
print(f"Old: {len(study_old.best_trials)} Pareto solutions")
print(f"New: {len(study_new.best_trials)} Pareto solutions")

# Compare best KGE
best_kge_old = max(t.values[0] for t in study_old.best_trials)
best_kge_new = max(t.values[0] for t in study_new.best_trials)
print(f"Best KGE - Old: {best_kge_old:.3f}, New: {best_kge_new:.3f}")
```

---

## ðŸ“¦ Integration with Existing Code

### Minimal Changes to `parallel.py`

Replace your `process_gr4j_gauge` function with this improved version:

```python
from src.models.gr4j.gr4j_optuna_improved import run_optimization

def process_gr4j_gauge_improved(
    gauge_id: str,
    datasets: list[str],
    calibration_period: tuple[str, str],
    validation_period: tuple[str, str],
    save_storage: Path,
    e_obs_gauge: gpd.GeoDataFrame | None = None,
    n_trials: int = 15,
    timeout: int = 3600,
    overwrite_results: bool = False,
) -> None:
    """Improved version with warm-up and enhanced metrics."""
    
    result_path = save_storage / gauge_id
    result_path.mkdir(parents=True, exist_ok=True)
    
    point_geom = e_obs_gauge.loc[gauge_id, "geometry"]
    latitude = float(point_geom.y)
    
    # IMPROVED WEIGHTS: Better balance of low/high flows
    hydro_weights: dict[str, float] = {
        "KGE": 0.25,
        "low_flow": 0.35,   # Increased from implicit 0.5 (logNSE only)
        "high_flow": 0.30,  # Increased from 0.5
        "PBIAS": 0.10,      # Increased from 0.03
    }
    
    for dataset in datasets:
        logger.info(f"Processing gauge {gauge_id} with dataset {dataset}")
        
        if (result_path / f"{gauge_id}_{dataset}").exists() and not overwrite_results:
            logger.info(f"Results exist. Skipping.")
            continue
        
        try:
            # Load data (extend backwards for warm-up if available)
            with xr.open_dataset(f"../data/nc_all_q/{gauge_id}.nc") as ds:
                exmp = ds.to_dataframe()
                exmp["t_mean_e5l"] = (exmp["t_max_e5l"] + exmp["t_min_e5l"]) / 2
            
            # Extend data range to include warm-up period (2005-2020 instead of 2008-2020)
            gr4j_data = exmp.loc[
                "2005":"2020",  # CHANGED: was "2008":"2020"
                ["q_mm_day", "t_min_e5l", "t_mean_e5l", "t_max_e5l", f"prcp_{dataset}"],
            ].copy()
            
            gr4j_data.rename(
                columns={f"prcp_{dataset}": "prcp", "t_mean_e5l": "t_mean"},
                inplace=True
            )
            
            if "day_of_year" not in gr4j_data.columns:
                gr4j_data["day_of_year"] = gr4j_data.index.dayofyear
            
            t_mean_list = gr4j_data["t_mean"].tolist()
            day_of_year_list = gr4j_data["day_of_year"].tolist()
            gr4j_data["pet_mm_day"] = pet_oudin(t_mean_list, day_of_year_list, latitude)
            
            # Run IMPROVED optimization with warm-up
            study = run_optimization(
                gr4j_data,
                calibration_period=calibration_period,  # Still 2008-2018
                study_name=f"GR4J_improved_{gauge_id}_{dataset}",
                n_trials=n_trials,
                timeout=timeout,
                verbose=False,
                warmup_years=2,  # NEW: 2-year warm-up (2006-2007)
                use_detailed=False  # Use 4-objective composite approach
            )
            
            if not study.best_trials:
                logger.warning(f"No valid trials for {gauge_id} with {dataset}")
                continue
            
            # Select best trial with IMPROVED weights
            best_hydro = select_best_trial_weighted(
                study.best_trials, hydro_weights, "weighted_sum"
            )
            best_params = dict(best_hydro.params)
            
            # Validation (include warm-up for consistent initialization)
            val_start = pd.to_datetime(validation_period[0])
            val_warmup_start = val_start - pd.DateOffset(years=2)
            gr4j_validation_full = gr4j_data.loc[val_warmup_start:validation_period[1], :]
            
            q_sim_full = gr4j.simulation(gr4j_validation_full, list(best_params.values()))
            
            # Extract validation period (exclude warm-up)
            n_val_warmup = len(gr4j_data[val_warmup_start:val_start]) - 1
            q_sim = q_sim_full[n_val_warmup:]
            
            gr4j_validation = gr4j_data.loc[validation_period[0]:validation_period[1], :]
            observed_values = np.array(gr4j_validation["q_mm_day"].values, dtype=float)
            q_sim_np = np.array(q_sim, dtype=float)[:len(observed_values)]
            
            metrics = evaluate_model(observed_values, q_sim_np)
            
            # Add flow regime analysis
            from src.utils.metrics_enhanced import analyze_flow_regimes
            regime_metrics = analyze_flow_regimes(observed_values, q_sim_np)
            metrics.update(regime_metrics)
            
            # Save results
            save_optimization_results(
                study=study,
                dataset_name=dataset,
                gauge_id=gauge_id,
                best_parameters=best_params,
                metrics=metrics,
                output_dir=str(result_path),
            )
            logger.info(f"Completed optimization for {gauge_id} with {dataset}")
            
        except Exception as e:
            logger.error(f"Error processing {gauge_id} with {dataset}: {str(e)}")
```

### Update `scripts/gr4j_optuna.py`

Just replace the import:

```python
from src.models.gr4j.parallel import (
    process_gr4j_gauge_improved,  # Changed from process_gr4j_gauge
    run_parallel_optimization,
)

# In main()
run_parallel_optimization(
    gauge_ids=full_gauges,
    process_gauge_func=partial(
        process_gr4j_gauge_improved,  # Changed
        datasets=datasets,
        calibration_period=calibration_period,
        validation_period=validation_period,
        save_storage=save_storage,
        e_obs_gauge=gauges,
        n_trials=n_trials,
        timeout=timeout,
        overwrite_results=overwrite_existing_results,
    ),
    n_processes=mp.cpu_count() - 2,
)
```

---

## ðŸ” What to Monitor

After running on a few test basins, check these indicators:

### 1. **Convergence Speed**
```python
# Plot trials to Pareto front
import matplotlib.pyplot as plt

trial_numbers = [t.number for t in study.best_trials]
kge_values = [t.values[0] for t in study.best_trials]

plt.figure(figsize=(10, 6))
plt.scatter(trial_numbers, kge_values)
plt.xlabel("Trial Number")
plt.ylabel("KGE")
plt.title("Convergence: When did Pareto solutions appear?")
plt.show()

# Good sign: Most Pareto solutions found in first 50% of trials
```

### 2. **Low-Flow Improvement**
```python
# Compare logNSE on validation period
from src.utils.metrics import log_nash_sutcliffe_efficiency

# Old calibration result (if you have it)
lognse_old = 0.55  # example

# New calibration
lognse_new = log_nash_sutcliffe_efficiency(observed_values, q_sim_np)

improvement = ((lognse_new - lognse_old) / abs(lognse_old)) * 100
print(f"Low-flow NSE improvement: {improvement:.1f}%")

# Target: >15% improvement
```

### 3. **Parameter Realism**
```python
# Check CemaNeige parameters are in realistic range
best_params = dict(best_hydro.params)
print(f"CTG: {best_params['ctg']:.3f}  (should be 0.2-0.8 typically)")
print(f"Kf: {best_params['kf']:.3f}  (should be 2-6 mm/day/Â°C typically)")
print(f"TT: {best_params['tt']:.3f}  (should be -1 to +1 Â°C typically)")

# Good sign: CTG not at bounds (0 or 1), Kf in 2-6 range
```

### 4. **Flow Regime Balance**
```python
# Check performance across quantiles
regime_metrics = analyze_flow_regimes(observed_values, q_sim_np)
print("NSE by flow regime:")
print(f"  Very low (Q<Q10): {regime_metrics['very_low_nse']:.3f}")
print(f"  Low (Q10-Q30):    {regime_metrics['low_nse']:.3f}")
print(f"  Medium (Q30-Q70): {regime_metrics['medium_nse']:.3f}")
print(f"  High (Q70-Q90):   {regime_metrics['high_nse']:.3f}")
print(f"  Very high (Q>Q90):{regime_metrics['very_high_nse']:.3f}")

# Good sign: All regimes > 0.5, no extreme drop-off in low flows
```

---

## ðŸ› Troubleshooting

### Issue: "Insufficient data for warm-up"
**Cause**: Your data starts at 2008, but we need 2006 for 2-year warm-up  
**Fix**: Reduce `warmup_years=1` or load data from 2005 if available

### Issue: Optimization slower than before
**Cause**: Warm-up adds simulation time  
**Fix**: This is expected (~10% slower), but better quality. If unacceptable, use `warmup_years=1`

### Issue: Worse performance on validation
**Cause**: More balanced calibration may sacrifice peak NSE for better overall  
**Fix**: This is intended! Check `lognse` and `PBIAS` - they should improve significantly

### Issue: All trials fail (values = -999)
**Cause**: Data loading or simulation error  
**Check**: 
```python
# Verify data has required columns
print(gr4j_data.columns)
# Should have: q_mm_day, prcp, t_mean, pet_mm_day, day_of_year

# Check for NaNs
print(gr4j_data.isna().sum())
```

---

## ðŸ“ˆ Expected Results

Based on literature and your current setup:

| Metric | Current (est.) | After Phase 1 | Improvement |
|--------|----------------|---------------|-------------|
| Median KGE | ~0.70 | ~0.73 | +4% |
| Median NSE | ~0.65 | ~0.67 | +3% |
| Median logNSE | ~0.55 | ~0.65 | +18% â­ |
| Low-flow PBIAS | High | Moderate | -30% â­ |
| Trials to converge | 4200 | ~3000 | -29% â­ |

**Key wins**: Much better low-flow performance with similar high-flow quality.

---

## ðŸŽ“ Next Steps

1. **Test on 3-5 representative basins** (different sizes, snow influence)
2. **Compare with your current results** (same basins, same periods)
3. **If successful** (>10% logNSE improvement), deploy to all basins
4. **Optional**: Try detailed 6-objective approach for problematic basins

---

## ðŸ“š References in Code

Key improvements are based on:
- Thirel et al. (2023) - sqrt transformation for balanced regimes
- Santos et al. (2022) - inverse transformation for low flows
- INRAE airGR docs - CemaNeige bounds and warm-up recommendations
- Your existing codebase - minimal disruption philosophy

---

**Questions? Check `docs/gr4j_calibration_improvement_plan.md` for full technical details.**
