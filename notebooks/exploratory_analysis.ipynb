{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3121c93c",
   "metadata": {},
   "source": [
    "# TFT Hydrological Forecasting - Exploratory Analysis\n",
    "\n",
    "This notebook provides an example of how to use the TFT predictions framework for hydrological forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our framework\n",
    "from src.config.settings import Settings\n",
    "from src.data.loaders import prepare_model_data, split_time_series\n",
    "from src.models.tft_model import TFTModelWrapper\n",
    "from src.evaluation.metrics import create_metrics_dataframe\n",
    "from src.utils.helpers import set_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf6734",
   "metadata": {},
   "source": [
    "## Configuration Setup\n",
    "\n",
    "First, let's set up our configuration for the TFT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = Path(\"configs/single_gauge.yaml\")\n",
    "\n",
    "if config_path.exists():\n",
    "    settings = Settings.from_yaml(config_path)\n",
    "    print(f\"Loaded configuration from {config_path}\")\n",
    "else:\n",
    "    settings = Settings()\n",
    "    print(\"Using default configuration\")\n",
    "\n",
    "# Update static parameters based on target\n",
    "settings.update_static_parameters()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_random_seed(settings.model.random_state)\n",
    "\n",
    "print(f\"Target variable: {settings.data.hydro_target}\")\n",
    "print(f\"Input meteorological variables: {settings.data.meteo_input}\")\n",
    "print(f\"Model configuration: {settings.model.input_chunk_length} -> {settings.model.output_chunk_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0276df",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "\n",
    "Let's load some sample data and explore its characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa380e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example gauge IDs (replace with your actual gauge IDs)\n",
    "sample_gauge_ids = [\"gauge_001\", \"gauge_002\"]  \n",
    "\n",
    "try:\n",
    "    # Load data for sample gauges\n",
    "    target_series, covariate_series = prepare_model_data(\n",
    "        settings, \n",
    "        area_filter=sample_gauge_ids\n",
    "    )\n",
    "    \n",
    "    print(f\"Loaded data for {len(target_series) if isinstance(target_series, list) else 1} gauge(s)\")\n",
    "    \n",
    "    # Display basic information about the first series\n",
    "    first_series = target_series[0] if isinstance(target_series, list) else target_series\n",
    "    print(f\"\\nFirst series:\")\n",
    "    print(f\"Length: {len(first_series)} time steps\")\n",
    "    print(f\"Date range: {first_series.start_time()} to {first_series.end_time()}\")\n",
    "    print(f\"Variables: {first_series.columns.tolist()}\")\n",
    "    \n",
    "    if first_series.static_covariates is not None:\n",
    "        print(f\"Static covariates: {first_series.static_covariates.columns.tolist()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"This is expected if you don't have the actual data files.\")\n",
    "    print(\"The framework is ready to use once you provide the correct data paths.\")\n",
    "    \n",
    "    # Create synthetic data for demonstration\n",
    "    print(\"\\nCreating synthetic data for demonstration...\")\n",
    "    \n",
    "    dates = pd.date_range('2020-01-01', periods=365, freq='D')\n",
    "    \n",
    "    # Synthetic discharge data with seasonal pattern\n",
    "    discharge = 10 + 5 * np.sin(2 * np.pi * np.arange(365) / 365) + np.random.normal(0, 1, 365)\n",
    "    \n",
    "    # Synthetic meteorological data\n",
    "    precipitation = np.maximum(0, np.random.exponential(2, 365))\n",
    "    temp_max = 15 + 10 * np.sin(2 * np.pi * np.arange(365) / 365) + np.random.normal(0, 2, 365)\n",
    "    temp_min = temp_max - 5 - np.random.exponential(2, 365)\n",
    "    \n",
    "    # Create synthetic TimeSeries\n",
    "    from darts import TimeSeries\n",
    "    \n",
    "    target_series = TimeSeries.from_times_and_values(\n",
    "        times=dates,\n",
    "        values=discharge,\n",
    "        columns=[\"discharge\"]\n",
    "    )\n",
    "    \n",
    "    covariate_series = TimeSeries.from_times_and_values(\n",
    "        times=dates,\n",
    "        values=np.column_stack([precipitation, temp_max, temp_min]),\n",
    "        columns=[\"precipitation\", \"temp_max\", \"temp_min\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"Created synthetic data with {len(target_series)} time steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850b16a",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Let's visualize the time series data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3141604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series data\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot target variable\n",
    "target_series.plot(ax=axes[0])\n",
    "axes[0].set_title(f\"Target Variable: {settings.data.hydro_target}\")\n",
    "axes[0].set_ylabel(\"Discharge\")\n",
    "\n",
    "# Plot meteorological variables\n",
    "if covariate_series is not None:\n",
    "    covariate_series.plot(ax=axes[1])\n",
    "    axes[1].set_title(\"Meteorological Variables\")\n",
    "    axes[1].set_ylabel(\"Values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nTarget Series Statistics:\")\n",
    "target_df = target_series.pd_dataframe()\n",
    "print(target_df.describe())\n",
    "\n",
    "if covariate_series is not None:\n",
    "    print(\"\\nCovariate Series Statistics:\")\n",
    "    cov_df = covariate_series.pd_dataframe()\n",
    "    print(cov_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04fae3",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "\n",
    "Split the data into train, validation, and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_target, val_target, test_target = split_time_series(\n",
    "    target_series,\n",
    "    train_split=settings.training.train_split,\n",
    "    val_split=settings.training.val_split\n",
    ")\n",
    "\n",
    "train_cov, val_cov, test_cov = None, None, None\n",
    "if covariate_series is not None:\n",
    "    train_cov, val_cov, test_cov = split_time_series(\n",
    "        covariate_series,\n",
    "        train_split=settings.training.train_split,\n",
    "        val_split=settings.training.val_split\n",
    "    )\n",
    "\n",
    "print(f\"Train set length: {len(train_target)}\")\n",
    "print(f\"Validation set length: {len(val_target)}\")\n",
    "print(f\"Test set length: {len(test_target)}\")\n",
    "\n",
    "# Visualize the split\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "train_target.plot(ax=ax, label=\"Train\")\n",
    "val_target.plot(ax=ax, label=\"Validation\")\n",
    "test_target.plot(ax=ax, label=\"Test\")\n",
    "\n",
    "ax.set_title(\"Data Split Visualization\")\n",
    "ax.set_ylabel(\"Discharge\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa8542",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Now let's train a TFT model on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust model settings for faster training in notebook\n",
    "settings.model.n_epochs = 10  # Reduced for demonstration\n",
    "settings.model.batch_size = 8\n",
    "settings.model.hidden_size = 32\n",
    "\n",
    "print(\"Training TFT model...\")\n",
    "print(f\"Configuration: {settings.model.input_chunk_length} -> {settings.model.output_chunk_length}\")\n",
    "print(f\"Epochs: {settings.model.n_epochs}\")\n",
    "\n",
    "# Initialize model\n",
    "model_wrapper = TFTModelWrapper(settings)\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    model_wrapper.train(\n",
    "        target_series=train_target,\n",
    "        val_series=val_target,\n",
    "        covariates=train_cov,\n",
    "        val_covariates=val_cov\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining completed successfully!\")\n",
    "    \n",
    "    # Get training history\n",
    "    history = model_wrapper.get_training_history()\n",
    "    \n",
    "    if history[\"train\"] and history[\"val\"]:\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(history[\"train\"], label=\"Training Loss\")\n",
    "        plt.plot(history[\"val\"], label=\"Validation Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training History\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Final training loss: {history['train'][-1]:.4f}\")\n",
    "        print(f\"Final validation loss: {history['val'][-1]:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")\n",
    "    print(\"This might be due to insufficient data or resource constraints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1971b",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Let's make predictions and evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904da7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Make predictions on test set\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = model_wrapper.predict(\n",
    "        series=train_target,\n",
    "        covariates=train_cov,\n",
    "        n=len(test_target)\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated {len(predictions)} predictions\")\n",
    "    \n",
    "    # Visualize predictions vs actual\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    test_target.plot(ax=ax, label=\"Actual\", color=\"blue\")\n",
    "    predictions.plot(ax=ax, label=\"Predicted\", color=\"red\", alpha=0.7)\n",
    "    \n",
    "    ax.set_title(\"Predictions vs Actual\")\n",
    "    ax.set_ylabel(\"Discharge\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    print(\"\\nCalculating evaluation metrics...\")\n",
    "    metrics_df = model_wrapper.evaluate([predictions], [test_target])\n",
    "    \n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(\"=\" * 30)\n",
    "    for col in [\"NSE\", \"KGE\", \"RMSE\", \"correlation\"]:\n",
    "        if col in metrics_df.columns:\n",
    "            value = metrics_df.iloc[0][col]\n",
    "            if not pd.isna(value):\n",
    "                print(f\"{col}: {value:.4f}\")\n",
    "    \n",
    "    # Show full metrics table\n",
    "    print(\"\\nFull Metrics Table:\")\n",
    "    print(metrics_df.round(4))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Prediction/evaluation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55904af6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the basic workflow for using the TFT predictions framework:\n",
    "\n",
    "1. **Configuration**: Setting up model and data parameters\n",
    "2. **Data Loading**: Loading and preparing hydrological time series data\n",
    "3. **Visualization**: Exploring the data characteristics\n",
    "4. **Training**: Training the TFT model\n",
    "5. **Evaluation**: Making predictions and calculating performance metrics\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Scale up**: Use the full dataset with more gauges and longer time series\n",
    "- **Hyperparameter tuning**: Optimize model parameters for better performance\n",
    "- **Multi-gauge training**: Train on multiple gauges simultaneously\n",
    "- **Advanced evaluation**: Include confidence intervals and uncertainty quantification\n",
    "\n",
    "### Scripts Available\n",
    "\n",
    "For production use, consider using the command-line scripts:\n",
    "\n",
    "```bash\n",
    "# Train single gauge model\n",
    "python scripts/train_single_gauge.py --gauge-id GAUGE_001 --config configs/single_gauge.yaml\n",
    "\n",
    "# Train multi-gauge model  \n",
    "python scripts/train_multi_gauge.py --gauge-list gauge_list.txt --config configs/multi_gauge.yaml\n",
    "\n",
    "# Make predictions\n",
    "python scripts/predict.py --model-path models/tft_model.pkl --gauge-ids GAUGE_001 GAUGE_002\n",
    "\n",
    "# Evaluate model\n",
    "python scripts/evaluate.py --model-path models/tft_model.pkl --create-plots\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
