{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a6fd3a",
   "metadata": {},
   "source": [
    "# Model Metrics Overview: GR4J, HBV, RFR with Different Meteo Sources\n",
    "\n",
    "Overview of performance metrics for different hydrological models trained with different meteorological data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d212522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Base paths for optimization results\n",
    "BASE_PATHS = {\n",
    "    \"GR4J\": Path(\"/home/dmbrmv/Development/Dissertation/data/optimization/gr4j_simple\"),\n",
    "    \"HBV\": Path(\"/home/dmbrmv/Development/Dissertation/data/optimization/hbv_simple\"),\n",
    "    \"RFR\": Path(\"/home/dmbrmv/Development/Dissertation/data/optimization/rfr_simple\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f12e2e",
   "metadata": {},
   "source": [
    "## Load Model Results and Metrics\n",
    "\n",
    "Extract performance metrics from all model directories across different meteorological sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89f862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GR4J results from /home/dmbrmv/Development/Dissertation/data/optimization/gr4j_simple...\n",
      "  Found 637 gauges\n",
      "Loading HBV results from /home/dmbrmv/Development/Dissertation/data/optimization/hbv_simple...\n",
      "  Found 37 gauges\n",
      "Loading RFR results from /home/dmbrmv/Development/Dissertation/data/optimization/rfr_simple...\n",
      "  Found 0 gauges\n",
      "\n",
      "Sample meteo sources found:\n",
      "  GR4J: ['mswep', 'gpcp', 'e5l', 'e5']\n",
      "  HBV: []\n"
     ]
    }
   ],
   "source": [
    "def load_metrics_from_directory(base_path: Path) -> dict:\n",
    "    \"\"\"Load all metrics from model optimization directory.\n",
    "\n",
    "    Args:\n",
    "        base_path: Path to model optimization directory.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with structure {gauge_id: {meteo_source: metrics_dict}}.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for gauge_dir in base_path.iterdir():\n",
    "        if not gauge_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        gauge_id = gauge_dir.name\n",
    "        results[gauge_id] = {}\n",
    "\n",
    "        # Find all metrics files\n",
    "        for metrics_file in gauge_dir.glob(\"*_metrics.json\"):\n",
    "            # Extract meteo source from filename (e.g., \"10042_e5_metrics.json\")\n",
    "            parts = metrics_file.stem.split(\"_\")\n",
    "            meteo_source = \"_\".join(parts[1:-1])  # Get middle part(s)\n",
    "\n",
    "            try:\n",
    "                with open(metrics_file) as f:\n",
    "                    metrics = json.load(f)\n",
    "                    results[gauge_id][meteo_source] = metrics\n",
    "            except (json.JSONDecodeError, FileNotFoundError):\n",
    "                continue\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Load data for all models\n",
    "model_data = {}\n",
    "for model_name, base_path in BASE_PATHS.items():\n",
    "    print(f\"Loading {model_name} results from {base_path}...\")\n",
    "    model_data[model_name] = load_metrics_from_directory(base_path)\n",
    "    print(f\"  Found {len(model_data[model_name])} gauges\")\n",
    "\n",
    "print(\"\\nSample meteo sources found:\")\n",
    "for model_name, data in model_data.items():\n",
    "    if data:\n",
    "        first_gauge = next(iter(data.values()))\n",
    "        print(f\"  {model_name}: {list(first_gauge.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13051f",
   "metadata": {},
   "source": [
    "## Parse Meteorological Sources\n",
    "\n",
    "Identify and extract meteorological source information from the model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9a3b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All meteorological sources found: ['e5', 'e5l', 'gpcp', 'mswep']\n",
      "Total sources: 4\n"
     ]
    }
   ],
   "source": [
    "# Identify all unique meteo sources across all models\n",
    "all_meteo_sources = set()\n",
    "for model_data_dict in model_data.values():\n",
    "    for gauge_metrics in model_data_dict.values():\n",
    "        all_meteo_sources.update(gauge_metrics.keys())\n",
    "\n",
    "all_meteo_sources = sorted(list(all_meteo_sources))\n",
    "print(f\"All meteorological sources found: {all_meteo_sources}\")\n",
    "print(f\"Total sources: {len(all_meteo_sources)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b94e2f",
   "metadata": {},
   "source": [
    "## Aggregate Metrics by Model and Source\n",
    "\n",
    "Group metrics by model type and meteorological source. Calculate mean and median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f7519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation complete.\n",
      "\n",
      "Metrics available for each source:\n",
      "  GR4J: ['NSE', 'KGE', 'PBIAS', 'RMSE', 'MAE', 'logNSE', 'R2', 'PFE']\n"
     ]
    }
   ],
   "source": [
    "def aggregate_metrics(model_data_dict: dict) -> dict:\n",
    "    \"\"\"Aggregate metrics by meteo source.\n",
    "\n",
    "    Args:\n",
    "        model_data_dict: Dictionary {gauge_id: {meteo_source: metrics}}.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary {meteo_source: {metric_name: list_of_values}}.\n",
    "    \"\"\"\n",
    "    aggregated = {}\n",
    "\n",
    "    for gauge_id, sources_dict in model_data_dict.items():\n",
    "        for meteo_source, metrics in sources_dict.items():\n",
    "            if meteo_source not in aggregated:\n",
    "                aggregated[meteo_source] = {}\n",
    "\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                if metric_name not in aggregated[meteo_source]:\n",
    "                    aggregated[meteo_source][metric_name] = []\n",
    "\n",
    "                # Only add numeric values\n",
    "                if isinstance(metric_value, (int, float)):\n",
    "                    aggregated[meteo_source][metric_name].append(metric_value)\n",
    "\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "# Aggregate metrics for each model\n",
    "aggregated_data = {}\n",
    "for model_name, model_dict in model_data.items():\n",
    "    aggregated_data[model_name] = aggregate_metrics(model_dict)\n",
    "\n",
    "print(\"Aggregation complete.\")\n",
    "print(\"\\nMetrics available for each source:\")\n",
    "for model_name in aggregated_data:\n",
    "    sample_source = next(iter(aggregated_data[model_name].keys()), None)\n",
    "    if sample_source:\n",
    "        metrics = aggregated_data[model_name][sample_source]\n",
    "        print(f\"  {model_name}: {list(metrics.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe0aeed",
   "metadata": {},
   "source": [
    "## Create Summary Statistics Table\n",
    "\n",
    "Build a summary table with mean and median values for all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85150891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary table shape: (4, 18)\n",
      "Columns: ['Model', 'Source', 'NSE_median', 'NSE_mean', 'KGE_median', 'KGE_mean', 'PBIAS_median', 'PBIAS_mean', 'RMSE_median', 'RMSE_mean', 'MAE_median', 'MAE_mean', 'logNSE_median', 'logNSE_mean', 'R2_median', 'R2_mean', 'PFE_median', 'PFE_mean']\n"
     ]
    }
   ],
   "source": [
    "def build_summary_table(aggregated_data: dict) -> pd.DataFrame:\n",
    "    \"\"\"Build summary statistics table.\n",
    "\n",
    "    Args:\n",
    "        aggregated_data: Dictionary {model: {source: {metric: [values]}}}.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with rows as Model-Source combinations and columns as metrics.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for model_name, sources_dict in aggregated_data.items():\n",
    "        for meteo_source, metrics_dict in sources_dict.items():\n",
    "            row = {\"Model\": model_name, \"Source\": meteo_source}\n",
    "\n",
    "            for metric_name, values in metrics_dict.items():\n",
    "                if values:\n",
    "                    values_array = np.array(values)\n",
    "                    row[f\"{metric_name}_median\"] = np.nanmedian(values_array)\n",
    "                    row[f\"{metric_name}_mean\"] = np.nanmean(values_array)\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Build the summary table\n",
    "summary_df = build_summary_table(aggregated_data)\n",
    "print(f\"Summary table shape: {summary_df.shape}\")\n",
    "print(f\"Columns: {list(summary_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2fe56e",
   "metadata": {},
   "source": [
    "## Display Comparison Results\n",
    "\n",
    "Show the summary statistics table with performance metrics for all model and meteo source combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee5f619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "SUMMARY STATISTICS: Model Performance by Meteorological Source\n",
      "========================================================================================================================\n",
      "Model Source  NSE_median  NSE_mean  KGE_median  KGE_mean  PBIAS_median  PBIAS_mean  RMSE_median  RMSE_mean  MAE_median  MAE_mean  logNSE_median  logNSE_mean  R2_median  R2_mean  PFE_median   PFE_mean\n",
      " GR4J  mswep    0.431638 -2.577517    0.571123  0.219075      1.850627    6.968146     0.579088   0.789950    0.309604  0.427966       0.400735    -0.280626   0.591546 0.558832  -15.393852  -0.072156\n",
      " GR4J   gpcp    0.166081 -1.850846    0.193970  0.010754      3.387080   18.062986     0.642770   0.962069    0.416976  0.577994       0.037571    -0.495839   0.381519 0.387355  -43.299618 -28.161330\n",
      " GR4J    e5l    0.514289 -2.671481    0.623488  0.227880      1.160937    6.101205     0.550928   0.732269    0.279181  0.376203       0.539744    -0.288703   0.670012 0.613873   -9.752190   6.409423\n",
      " GR4J     e5    0.449891 -3.133478    0.592185  0.194092      1.029173    6.989282     0.563082   0.759800    0.288540  0.403599       0.497500    -0.202565   0.631277 0.581021  -14.351303   3.285351\n",
      "========================================================================================================================\n",
      "\n",
      "\n",
      "KEY FINDINGS:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Total model-source combinations: 4\n",
      "Unique metrics tracked: 8\n",
      "Metrics: ['KGE', 'MAE', 'NSE', 'PBIAS', 'PFE', 'R2', 'RMSE', 'logNSE']\n",
      "\n",
      "Models: ['GR4J']\n",
      "Data sources: ['mswep', 'gpcp', 'e5l', 'e5']\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display full summary table\n",
    "print(\"=\" * 120)\n",
    "print(\"SUMMARY STATISTICS: Model Performance by Meteorological Source\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "if len(summary_df) > 0:\n",
    "    print(summary_df.to_string(index=False))\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    # Create a pivot view for better comparison\n",
    "    print(\"\\n\\nKEY FINDINGS:\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    # Get unique metrics\n",
    "    all_columns = summary_df.columns.tolist()\n",
    "    metric_names = set()\n",
    "    for col in all_columns:\n",
    "        if \"_median\" in col:\n",
    "            metric_names.add(col.replace(\"_median\", \"\"))\n",
    "\n",
    "    print(f\"Total model-source combinations: {len(summary_df)}\")\n",
    "    print(f\"Unique metrics tracked: {len(metric_names)}\")\n",
    "    print(f\"Metrics: {sorted(metric_names)}\")\n",
    "    print(f\"\\nModels: {summary_df['Model'].unique().tolist()}\")\n",
    "    print(f\"Data sources: {summary_df['Source'].unique().tolist()}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No data loaded. Please ensure metrics files exist in:\")\n",
    "    for model_name, base_path in BASE_PATHS.items():\n",
    "        print(f\"   - {model_name}: {base_path}\")\n",
    "    print(\n",
    "        \"\\nExpected file structure: {model_dir}/{gauge_id}/{gauge_id}_{source}_metrics.json\"\n",
    "    )\n",
    "print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888f35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camels_ru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
