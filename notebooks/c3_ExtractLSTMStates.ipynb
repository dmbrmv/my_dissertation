{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "imports",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.1+cu128\n",
            "CUDA available: True\n",
            "CUDA device: NVIDIA GeForce RTX 4080 SUPER\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "from neuralhydrology.datasetzoo import get_dataset\n",
        "from neuralhydrology.datautils.utils import load_scaler\n",
        "from neuralhydrology.modelzoo.cudalstm import CudaLSTM\n",
        "from neuralhydrology.modelzoo.customlstm import CustomLSTM\n",
        "from neuralhydrology.utils.config import Config\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# LSTM State Extraction for All Gauges\n",
        "\n",
        "This notebook properly extracts LSTM hidden states (h_n) and cell states (c_n) for **each gauge** separately.\n",
        "\n",
        "**Key insight**: The previous approach only extracted states from the first batch (â‰ˆ1 gauge).\n",
        "This notebook iterates through ALL samples and organizes states by gauge ID.\n",
        "\n",
        "**Requirements**: This notebook requires PyTorch and CUDA. Run on a machine with GPU support.\n",
        "\n",
        "Reference: https://neuralhydrology.readthedocs.io/en/latest/tutorials/inspect-lstm.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8d1abf00",
      "metadata": {},
      "outputs": [],
      "source": [
        "def best_epoch_finder(validation_dir: Path) -> int:\n",
        "    \"\"\"Find the best epoch based on median NSE across validation metrics.\n",
        "\n",
        "    Args:\n",
        "        validation_dir: Path to the validation directory containing epoch subdirectories\n",
        "\n",
        "    Returns:\n",
        "        The epoch number with the highest median NSE\n",
        "    \"\"\"\n",
        "    epoch_median_nse = {}\n",
        "\n",
        "    # Iterate through all epoch directories\n",
        "    for epoch_dir in sorted(validation_dir.glob(\"model_epoch*\")):\n",
        "        metrics_file = epoch_dir / \"validation_metrics.csv\"\n",
        "\n",
        "        if not metrics_file.exists():\n",
        "            continue\n",
        "\n",
        "        # Read validation metrics CSV\n",
        "        df = pd.read_csv(metrics_file)\n",
        "\n",
        "        # Extract epoch number from directory name (e.g., \"model_epoch030\" -> 30)\n",
        "        epoch_num = int(epoch_dir.name.split(\"model_epoch\")[1])\n",
        "\n",
        "        # Calculate median NSE across all basins\n",
        "        median_nse = df[\"NSE\"].median()\n",
        "        epoch_median_nse[epoch_num] = median_nse\n",
        "\n",
        "    if not epoch_median_nse:\n",
        "        raise ValueError(f\"No validation metrics found in {validation_dir}\")\n",
        "\n",
        "    # Return epoch with highest median NSE\n",
        "    best_epoch = max(epoch_median_nse, key=lambda x: epoch_median_nse[x])\n",
        "\n",
        "    return best_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "config",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Config file: ../data/lstm_configs/model_runs/FULL_cudalstm_q_mm_day_256_365_e5l_1201_193434/config.yml\n",
            "Output directory: ../data/optimization/lstm_states_per_gauge\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Configuration - Update these paths for your setup\n",
        "# =============================================================================\n",
        "\n",
        "# Path to your trained model config\n",
        "CONFIG_FILE = Path(\n",
        "    \"../data/lstm_configs/model_runs/FULL_cudalstm_q_mm_day_256_365_e5l_1201_193434/config.yml\"\n",
        ")\n",
        "\n",
        "# Model epoch to use (set to None to auto-detect best epoch)\n",
        "MODEL_EPOCH = best_epoch_finder(\n",
        "    Path(\n",
        "        \"../data/lstm_configs/model_runs/FULL_cudalstm_q_mm_day_256_365_e5l_1201_193434/validation\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Output directory for extracted states\n",
        "OUTPUT_DIR = Path(\"../data/optimization/lstm_states_per_gauge\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Batch size for processing (adjust based on GPU memory)\n",
        "# Larger = faster but more memory\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Device selection\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"  # For Apple Silicon\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Config file: {CONFIG_FILE}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "load_model",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model hidden size: 256"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sequence length: 365\n",
            "Loading model from: ../data/lstm_configs/model_runs/FULL_cudalstm_q_mm_day_256_365_e5l_1201_193434/model_epoch011.pt\n",
            "Model loaded successfully!\n",
            "Hidden size: 256\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Load trained model\n",
        "# =============================================================================\n",
        "\n",
        "# Load config\n",
        "cudalstm_config = Config(CONFIG_FILE)\n",
        "cudalstm_config.update_config(\n",
        "    {\n",
        "        \"data_dir\": Path(f\"../{cudalstm_config.data_dir}\"),\n",
        "        \"run_dir\": Path(f\"../{cudalstm_config.run_dir}\"),\n",
        "        \"test_basin_file\": Path(f\"../{cudalstm_config.test_basin_file}\"),\n",
        "        \"validation_basin_file\": Path(f\"../{cudalstm_config.validation_basin_file}\"),\n",
        "        \"train_basin_file\": Path(f\"../{cudalstm_config.train_basin_file}\"),\n",
        "    }\n",
        ")\n",
        "print(f\"Model hidden size: {cudalstm_config.hidden_size}\")\n",
        "print(f\"Sequence length: {cudalstm_config.seq_length}\")\n",
        "\n",
        "# Create CudaLSTM and load weights\n",
        "cuda_lstm = CudaLSTM(cfg=cudalstm_config)\n",
        "model_path = cudalstm_config.run_dir / f\"model_epoch{MODEL_EPOCH:03d}.pt\"\n",
        "print(f\"Loading model from: {model_path}\")\n",
        "\n",
        "model_weights = torch.load(str(model_path), map_location=DEVICE)\n",
        "cuda_lstm.load_state_dict(model_weights)\n",
        "\n",
        "# Create CustomLSTM and copy weights (for full state access)\n",
        "custom_lstm = CustomLSTM(cfg=cudalstm_config)\n",
        "custom_lstm.copy_weights(cuda_lstm)\n",
        "custom_lstm.to(DEVICE)\n",
        "custom_lstm.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(f\"Hidden size: {cudalstm_config.hidden_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "load_dataset",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of gauges in dataset: 996\n",
            "Total samples in dataset: 727080\n",
            "Samples per gauge (approx): 730\n",
            "First 5 gauge IDs: ['10042', '10044', '10048', '10058', '10059']\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Load test dataset\n",
        "# =============================================================================\n",
        "\n",
        "scaler = load_scaler(cudalstm_config.run_dir)\n",
        "dataset = get_dataset(cudalstm_config, is_train=False, period=\"test\", scaler=scaler)\n",
        "\n",
        "# Get list of basins (gauges) in the dataset\n",
        "# NeuralHydrology stores basin IDs in the dataset\n",
        "all_basins = (\n",
        "    dataset.basins if hasattr(dataset, \"basins\") else list(dataset.basin_id_map.keys())\n",
        ")\n",
        "n_basins = len(all_basins)\n",
        "\n",
        "print(f\"Number of gauges in dataset: {n_basins}\")\n",
        "print(f\"Total samples in dataset: {len(dataset)}\")\n",
        "print(f\"Samples per gauge (approx): {len(dataset) // n_basins}\")\n",
        "print(f\"First 5 gauge IDs: {all_basins[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "extract_states",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inspecting dataset structure...\n",
            "  lookup_table type: <class 'dict'>\n",
            "  lookup_table length: 727080\n",
            "  First 3 keys: [0, 1, 2]\n",
            "  Key types: [<class 'int'>, <class 'int'>, <class 'int'>]\n",
            "    [0] -> <class 'tuple'>: ('10042', [364])\n",
            "    [1] -> <class 'tuple'>: ('10042', [365])\n",
            "  Basin-related attributes: ['basins']\n",
            "\n",
            "Building sample-to-basin mapping...\n",
            "Total samples mapped: 727080\n",
            "Processing 2841 batches...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52e981538d2649cfb77987bcdd78b1a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting states:   0%|          | 0/2841 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracted states for 996 gauges\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Extract states for ALL gauges\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "def move_to_device(obj, device):\n",
        "    \"\"\"Recursively move tensors to device, handling nested structures.\"\"\"\n",
        "    if isinstance(obj, torch.Tensor):\n",
        "        return obj.to(device)\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: move_to_device(v, device) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        moved = [move_to_device(item, device) for item in obj]\n",
        "        return type(obj)(moved)\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "\n",
        "# Debug: inspect dataset structure to find basin mapping\n",
        "print(\"Inspecting dataset structure...\")\n",
        "print(f\"  lookup_table type: {type(dataset.lookup_table)}\")\n",
        "print(f\"  lookup_table length: {len(dataset.lookup_table)}\")\n",
        "\n",
        "# Inspect dict structure\n",
        "if isinstance(dataset.lookup_table, dict):\n",
        "    keys = list(dataset.lookup_table.keys())[:3]\n",
        "    print(f\"  First 3 keys: {keys}\")\n",
        "    print(f\"  Key types: {[type(k) for k in keys]}\")\n",
        "    for k in keys[:2]:\n",
        "        v = dataset.lookup_table[k]\n",
        "        print(f\"    [{k}] -> {type(v)}: {v}\")\n",
        "\n",
        "# Check for other attributes that might contain basin info\n",
        "if hasattr(dataset, \"basin_id_to_sample_index\"):\n",
        "    print(\n",
        "        f\"  basin_id_to_sample_index: {list(dataset.basin_id_to_sample_index.items())[:3]}\"\n",
        "    )\n",
        "if hasattr(dataset, \"sample_to_basin\"):\n",
        "    print(\"  sample_to_basin available\")\n",
        "if hasattr(dataset, \"_sample_index_to_basin\"):\n",
        "    print(\"  _sample_index_to_basin available\")\n",
        "\n",
        "# Print all relevant attributes\n",
        "attrs = [a for a in dir(dataset) if not a.startswith(\"_\") and \"basin\" in a.lower()]\n",
        "print(f\"  Basin-related attributes: {attrs}\")\n",
        "\n",
        "# Build sample-to-basin mapping based on dataset structure\n",
        "# lookup_table is {sample_index: (basin_id, date_info)}\n",
        "print(\"\\nBuilding sample-to-basin mapping...\")\n",
        "n_samples = len(dataset.lookup_table)\n",
        "sample_to_basin = [\"\"] * n_samples\n",
        "\n",
        "for sample_idx, (basin_id, date_info) in dataset.lookup_table.items():\n",
        "    sample_to_basin[sample_idx] = str(basin_id)\n",
        "\n",
        "print(f\"Total samples mapped: {len(sample_to_basin)}\")\n",
        "\n",
        "# Create dataloader with batch_sampler to track indices, or use sequential access\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,  # Keep order to track gauge IDs\n",
        "    collate_fn=dataset.collate_fn,\n",
        "    num_workers=0,  # Avoid multiprocessing issues\n",
        ")\n",
        "\n",
        "# Storage for per-gauge states\n",
        "# Key: gauge_id, Value: list of state arrays\n",
        "gauge_h_states = defaultdict(list)  # Hidden states\n",
        "gauge_c_states = defaultdict(list)  # Cell states\n",
        "\n",
        "print(f\"Processing {len(dataloader)} batches...\")\n",
        "\n",
        "sample_idx = 0  # Track global sample index\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Extracting states\")):\n",
        "        # Move batch to device (handles nested tensors)\n",
        "        batch_device = move_to_device(batch, DEVICE)\n",
        "\n",
        "        # Forward pass through CustomLSTM\n",
        "        output = custom_lstm(batch_device)\n",
        "\n",
        "        # Extract final timestep states: (batch, seq_len, hidden) -> (batch, hidden)\n",
        "        h_n = output[\"h_n\"][:, -1, :].cpu().numpy()  # Hidden state\n",
        "        c_n = output[\"c_n\"][:, -1, :].cpu().numpy()  # Cell state\n",
        "\n",
        "        batch_size_actual = len(h_n)\n",
        "\n",
        "        # Store states by gauge using the pre-built mapping\n",
        "        for i in range(batch_size_actual):\n",
        "            gauge_id = sample_to_basin[sample_idx]\n",
        "            gauge_h_states[gauge_id].append(h_n[i])\n",
        "            gauge_c_states[gauge_id].append(c_n[i])\n",
        "            sample_idx += 1\n",
        "\n",
        "print(f\"\\nExtracted states for {len(gauge_h_states)} gauges\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "verify_extraction",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per-gauge sample counts:\n",
            "  Min samples per gauge: 730\n",
            "  Max samples per gauge: 730\n",
            "  Mean samples per gauge: 730.0\n",
            "  10042: 730 samples\n",
            "  10044: 730 samples\n",
            "  10048: 730 samples\n",
            "  10058: 730 samples\n",
            "  10059: 730 samples\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Verify extraction\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Per-gauge sample counts:\")\n",
        "sample_counts = {g: len(states) for g, states in gauge_h_states.items()}\n",
        "\n",
        "print(f\"  Min samples per gauge: {min(sample_counts.values())}\")\n",
        "print(f\"  Max samples per gauge: {max(sample_counts.values())}\")\n",
        "print(f\"  Mean samples per gauge: {np.mean(list(sample_counts.values())):.1f}\")\n",
        "\n",
        "# Show first few gauges\n",
        "for gauge_id in list(gauge_h_states.keys())[:5]:\n",
        "    print(f\"  {gauge_id}: {len(gauge_h_states[gauge_id])} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "save_states",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving per-gauge state files...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71a35366ec684126aea2fd095a58c359",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving:   0%|          | 0/996 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved 996 state files to ../data/optimization/lstm_states_per_gauge\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Save states - Option 1: One file per gauge\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Saving per-gauge state files...\")\n",
        "\n",
        "for gauge_id in tqdm(gauge_h_states.keys(), desc=\"Saving\"):\n",
        "    h_states = np.array(gauge_h_states[gauge_id])  # Shape: (n_days, hidden_size)\n",
        "    c_states = np.array(gauge_c_states[gauge_id])  # Shape: (n_days, hidden_size)\n",
        "\n",
        "    # Save as npz\n",
        "    output_file = OUTPUT_DIR / f\"{gauge_id}_states.npz\"\n",
        "    np.savez_compressed(output_file, h_n=h_states, c_n=c_states, gauge_id=gauge_id)\n",
        "\n",
        "print(f\"\\nSaved {len(gauge_h_states)} state files to {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "save_combined",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 730 timesteps per gauge (minimum across all gauges)\n",
            "\n",
            "Saved combined states:\n",
            "  File: ../data/optimization/lstm_states_per_gauge/all_gauges_states.npz\n",
            "  h_n shape: (996, 730, 256)\n",
            "  c_n shape: (996, 730, 256)\n",
            "  Gauges: 996\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Save states - Option 2: Combined file with all gauges\n",
        "# =============================================================================\n",
        "\n",
        "# Create combined arrays\n",
        "# This is useful for the correlation analysis\n",
        "\n",
        "all_gauge_ids = sorted(gauge_h_states.keys())\n",
        "hidden_size = len(gauge_h_states[all_gauge_ids[0]][0])\n",
        "\n",
        "# Find common number of timesteps (use minimum across gauges)\n",
        "min_timesteps = min(len(gauge_h_states[g]) for g in all_gauge_ids)\n",
        "print(f\"Using {min_timesteps} timesteps per gauge (minimum across all gauges)\")\n",
        "\n",
        "# Create arrays: (n_gauges, n_timesteps, hidden_size)\n",
        "n_gauges = len(all_gauge_ids)\n",
        "all_h_states = np.zeros((n_gauges, min_timesteps, hidden_size), dtype=np.float32)\n",
        "all_c_states = np.zeros((n_gauges, min_timesteps, hidden_size), dtype=np.float32)\n",
        "\n",
        "for i, gauge_id in enumerate(all_gauge_ids):\n",
        "    all_h_states[i] = np.array(gauge_h_states[gauge_id][:min_timesteps])\n",
        "    all_c_states[i] = np.array(gauge_c_states[gauge_id][:min_timesteps])\n",
        "\n",
        "# Save combined file\n",
        "combined_file = OUTPUT_DIR / \"all_gauges_states.npz\"\n",
        "np.savez_compressed(\n",
        "    combined_file,\n",
        "    h_n=all_h_states,  # Shape: (n_gauges, n_timesteps, hidden_size)\n",
        "    c_n=all_c_states,  # Shape: (n_gauges, n_timesteps, hidden_size)\n",
        "    gauge_ids=np.array(all_gauge_ids),  # Gauge ID ordering\n",
        "    hidden_size=hidden_size,\n",
        "    n_timesteps=min_timesteps,\n",
        ")\n",
        "\n",
        "print(\"\\nSaved combined states:\")\n",
        "print(f\"  File: {combined_file}\")\n",
        "print(f\"  h_n shape: {all_h_states.shape}\")\n",
        "print(f\"  c_n shape: {all_c_states.shape}\")\n",
        "print(f\"  Gauges: {n_gauges}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "summary",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "EXTRACTION COMPLETE\n",
            "======================================================================\n",
            "\n",
            "Extracted LSTM states for 996 gauges\n",
            "Hidden size: 256\n",
            "Timesteps per gauge: 730\n",
            "\n",
            "Output files:\n",
            "  Individual: ../data/optimization/lstm_states_per_gauge/<gauge_id>_states.npz\n",
            "  Combined:   ../data/optimization/lstm_states_per_gauge/all_gauges_states.npz\n",
            "\n",
            "To use in analysis notebook:\n",
            "```python\n",
            "# Load combined states\n",
            "states = np.load('data/optimization/lstm_states_per_gauge/all_gauges_states.npz')\n",
            "h_n = states['h_n']  # (n_gauges, n_timesteps, hidden_size)\n",
            "c_n = states['c_n']  # (n_gauges, n_timesteps, hidden_size)\n",
            "gauge_ids = states['gauge_ids']\n",
            "\n",
            "# Get states for specific gauge\n",
            "gauge_idx = np.where(gauge_ids == '12345')[0][0]\n",
            "gauge_h_states = h_n[gauge_idx]  # (n_timesteps, hidden_size)\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Summary\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"EXTRACTION COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nExtracted LSTM states for {len(gauge_h_states)} gauges\")\n",
        "print(f\"Hidden size: {hidden_size}\")\n",
        "print(f\"Timesteps per gauge: {min_timesteps}\")\n",
        "print(\"\\nOutput files:\")\n",
        "print(f\"  Individual: {OUTPUT_DIR}/<gauge_id>_states.npz\")\n",
        "print(f\"  Combined:   {combined_file}\")\n",
        "print(\"\\nTo use in analysis notebook:\")\n",
        "print(\"\"\"```python\n",
        "# Load combined states\n",
        "states = np.load('data/optimization/lstm_states_per_gauge/all_gauges_states.npz')\n",
        "h_n = states['h_n']  # (n_gauges, n_timesteps, hidden_size)\n",
        "c_n = states['c_n']  # (n_gauges, n_timesteps, hidden_size)\n",
        "gauge_ids = states['gauge_ids']\n",
        "\n",
        "# Get states for specific gauge\n",
        "gauge_idx = np.where(gauge_ids == '12345')[0][0]\n",
        "gauge_h_states = h_n[gauge_idx]  # (n_timesteps, hidden_size)\n",
        "```\"\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "phd_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
