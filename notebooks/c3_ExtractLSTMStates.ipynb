{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# LSTM State Extraction for All Gauges\n",
        "\n",
        "This notebook properly extracts LSTM hidden states (h_n) and cell states (c_n) for **each gauge** separately.\n",
        "\n",
        "**Key insight**: The previous approach only extracted states from the first batch (â‰ˆ1 gauge).\n",
        "This notebook iterates through ALL samples and organizes states by gauge ID.\n",
        "\n",
        "**Requirements**: This notebook requires PyTorch and CUDA. Run on a machine with GPU support.\n",
        "\n",
        "Reference: https://neuralhydrology.readthedocs.io/en/latest/tutorials/inspect-lstm.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from neuralhydrology.datasetzoo import get_dataset\n",
        "from neuralhydrology.datautils.utils import load_scaler\n",
        "from neuralhydrology.modelzoo.cudalstm import CudaLSTM\n",
        "from neuralhydrology.modelzoo.customlstm import CustomLSTM\n",
        "from neuralhydrology.utils.config import Config\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "config",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Configuration - Update these paths for your setup\n",
        "# =============================================================================\n",
        "\n",
        "# Path to your trained model config\n",
        "CONFIG_FILE = Path(\n",
        "    \"../data/lstm_configs/model_runs/cudalstm_q_mm_day_mswep_no_autocorr_static_1103_191754/config.yml\"\n",
        ")\n",
        "\n",
        "# Model epoch to use (set to None to auto-detect best epoch)\n",
        "MODEL_EPOCH = 24\n",
        "\n",
        "# Output directory for extracted states\n",
        "OUTPUT_DIR = Path(\"../data/optimization/lstm_states_per_gauge\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Batch size for processing (adjust based on GPU memory)\n",
        "# Larger = faster but more memory\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Device selection\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"  # For Apple Silicon\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Config file: {CONFIG_FILE}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_model",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Load trained model\n",
        "# =============================================================================\n",
        "\n",
        "# Load config\n",
        "cudalstm_config = Config(CONFIG_FILE)\n",
        "print(f\"Model hidden size: {cudalstm_config.hidden_size}\")\n",
        "print(f\"Sequence length: {cudalstm_config.seq_length}\")\n",
        "\n",
        "# Create CudaLSTM and load weights\n",
        "cuda_lstm = CudaLSTM(cfg=cudalstm_config)\n",
        "model_path = cudalstm_config.run_dir / f\"model_epoch{MODEL_EPOCH:03d}.pt\"\n",
        "print(f\"Loading model from: {model_path}\")\n",
        "\n",
        "model_weights = torch.load(str(model_path), map_location=DEVICE)\n",
        "cuda_lstm.load_state_dict(model_weights)\n",
        "\n",
        "# Create CustomLSTM and copy weights (for full state access)\n",
        "custom_lstm = CustomLSTM(cfg=cudalstm_config)\n",
        "custom_lstm.copy_weights(cuda_lstm)\n",
        "custom_lstm.to(DEVICE)\n",
        "custom_lstm.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(f\"Hidden size: {cudalstm_config.hidden_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_dataset",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Load test dataset\n",
        "# =============================================================================\n",
        "\n",
        "scaler = load_scaler(cudalstm_config.run_dir)\n",
        "dataset = get_dataset(cudalstm_config, is_train=False, period=\"test\", scaler=scaler)\n",
        "\n",
        "# Get list of basins (gauges) in the dataset\n",
        "# NeuralHydrology stores basin IDs in the dataset\n",
        "all_basins = (\n",
        "    dataset.basins if hasattr(dataset, \"basins\") else list(dataset.basin_id_map.keys())\n",
        ")\n",
        "n_basins = len(all_basins)\n",
        "\n",
        "print(f\"Number of gauges in dataset: {n_basins}\")\n",
        "print(f\"Total samples in dataset: {len(dataset)}\")\n",
        "print(f\"Samples per gauge (approx): {len(dataset) // n_basins}\")\n",
        "print(f\"First 5 gauge IDs: {all_basins[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extract_states",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Extract states for ALL gauges\n",
        "# =============================================================================\n",
        "\n",
        "# Create dataloader\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,  # Keep order to track gauge IDs\n",
        "    collate_fn=dataset.collate_fn,\n",
        "    num_workers=0,  # Avoid multiprocessing issues\n",
        ")\n",
        "\n",
        "# Storage for per-gauge states\n",
        "# Key: gauge_id, Value: list of state arrays\n",
        "gauge_h_states = defaultdict(list)  # Hidden states\n",
        "gauge_c_states = defaultdict(list)  # Cell states\n",
        "gauge_dates = defaultdict(list)  # Corresponding dates\n",
        "\n",
        "print(f\"Processing {len(dataloader)} batches...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Extracting states\")):\n",
        "        # Move batch to device\n",
        "        batch_device = {\n",
        "            k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v\n",
        "            for k, v in batch.items()\n",
        "        }\n",
        "\n",
        "        # Forward pass through CustomLSTM\n",
        "        output = custom_lstm(batch_device)\n",
        "\n",
        "        # Extract final timestep states: (batch, seq_len, hidden) -> (batch, hidden)\n",
        "        h_n = output[\"h_n\"][:, -1, :].cpu().numpy()  # Hidden state\n",
        "        c_n = output[\"c_n\"][:, -1, :].cpu().numpy()  # Cell state\n",
        "\n",
        "        # Get basin IDs and dates for this batch\n",
        "        # NeuralHydrology includes metadata in the batch\n",
        "        basin_ids = batch.get(\"basin\", batch.get(\"basin_id\", None))\n",
        "        dates = batch.get(\"date\", batch.get(\"end_date\", None))\n",
        "\n",
        "        if basin_ids is None:\n",
        "            # Fallback: infer from batch index and dataset structure\n",
        "            start_idx = batch_idx * BATCH_SIZE\n",
        "            end_idx = min(start_idx + len(h_n), len(dataset))\n",
        "            # This requires knowing the dataset's internal ordering\n",
        "            print(f\"Warning: Basin IDs not in batch. Using index-based assignment.\")\n",
        "            # You may need to adjust this based on your dataset structure\n",
        "            continue\n",
        "\n",
        "        # Store states by gauge\n",
        "        for i in range(len(h_n)):\n",
        "            gauge_id = (\n",
        "                str(basin_ids[i]) if not isinstance(basin_ids[i], str) else basin_ids[i]\n",
        "            )\n",
        "            gauge_h_states[gauge_id].append(h_n[i])\n",
        "            gauge_c_states[gauge_id].append(c_n[i])\n",
        "            if dates is not None:\n",
        "                gauge_dates[gauge_id].append(dates[i])\n",
        "\n",
        "print(f\"\\nExtracted states for {len(gauge_h_states)} gauges\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verify_extraction",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Verify extraction\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Per-gauge sample counts:\")\n",
        "sample_counts = {g: len(states) for g, states in gauge_h_states.items()}\n",
        "\n",
        "print(f\"  Min samples per gauge: {min(sample_counts.values())}\")\n",
        "print(f\"  Max samples per gauge: {max(sample_counts.values())}\")\n",
        "print(f\"  Mean samples per gauge: {np.mean(list(sample_counts.values())):.1f}\")\n",
        "\n",
        "# Show first few gauges\n",
        "for gauge_id in list(gauge_h_states.keys())[:5]:\n",
        "    print(f\"  {gauge_id}: {len(gauge_h_states[gauge_id])} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "save_states",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Save states - Option 1: One file per gauge\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Saving per-gauge state files...\")\n",
        "\n",
        "for gauge_id in tqdm(gauge_h_states.keys(), desc=\"Saving\"):\n",
        "    h_states = np.array(gauge_h_states[gauge_id])  # Shape: (n_days, hidden_size)\n",
        "    c_states = np.array(gauge_c_states[gauge_id])  # Shape: (n_days, hidden_size)\n",
        "\n",
        "    # Save as npz\n",
        "    output_file = OUTPUT_DIR / f\"{gauge_id}_states.npz\"\n",
        "    np.savez_compressed(output_file, h_n=h_states, c_n=c_states, gauge_id=gauge_id)\n",
        "\n",
        "print(f\"\\nSaved {len(gauge_h_states)} state files to {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "save_combined",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Save states - Option 2: Combined file with all gauges\n",
        "# =============================================================================\n",
        "\n",
        "# Create combined arrays\n",
        "# This is useful for the correlation analysis\n",
        "\n",
        "all_gauge_ids = sorted(gauge_h_states.keys())\n",
        "hidden_size = len(gauge_h_states[all_gauge_ids[0]][0])\n",
        "\n",
        "# Find common number of timesteps (use minimum across gauges)\n",
        "min_timesteps = min(len(gauge_h_states[g]) for g in all_gauge_ids)\n",
        "print(f\"Using {min_timesteps} timesteps per gauge (minimum across all gauges)\")\n",
        "\n",
        "# Create arrays: (n_gauges, n_timesteps, hidden_size)\n",
        "n_gauges = len(all_gauge_ids)\n",
        "all_h_states = np.zeros((n_gauges, min_timesteps, hidden_size), dtype=np.float32)\n",
        "all_c_states = np.zeros((n_gauges, min_timesteps, hidden_size), dtype=np.float32)\n",
        "\n",
        "for i, gauge_id in enumerate(all_gauge_ids):\n",
        "    all_h_states[i] = np.array(gauge_h_states[gauge_id][:min_timesteps])\n",
        "    all_c_states[i] = np.array(gauge_c_states[gauge_id][:min_timesteps])\n",
        "\n",
        "# Save combined file\n",
        "combined_file = OUTPUT_DIR / \"all_gauges_states.npz\"\n",
        "np.savez_compressed(\n",
        "    combined_file,\n",
        "    h_n=all_h_states,  # Shape: (n_gauges, n_timesteps, hidden_size)\n",
        "    c_n=all_c_states,  # Shape: (n_gauges, n_timesteps, hidden_size)\n",
        "    gauge_ids=np.array(all_gauge_ids),  # Gauge ID ordering\n",
        "    hidden_size=hidden_size,\n",
        "    n_timesteps=min_timesteps,\n",
        ")\n",
        "\n",
        "print(f\"\\nSaved combined states:\")\n",
        "print(f\"  File: {combined_file}\")\n",
        "print(f\"  h_n shape: {all_h_states.shape}\")\n",
        "print(f\"  c_n shape: {all_c_states.shape}\")\n",
        "print(f\"  Gauges: {n_gauges}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "summary",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Summary\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"EXTRACTION COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nExtracted LSTM states for {len(gauge_h_states)} gauges\")\n",
        "print(f\"Hidden size: {hidden_size}\")\n",
        "print(f\"Timesteps per gauge: {min_timesteps}\")\n",
        "print(f\"\\nOutput files:\")\n",
        "print(f\"  Individual: {OUTPUT_DIR}/<gauge_id>_states.npz\")\n",
        "print(f\"  Combined:   {combined_file}\")\n",
        "print(f\"\\nTo use in analysis notebook:\")\n",
        "print(\"\"\"```python\n",
        "# Load combined states\n",
        "states = np.load('data/optimization/lstm_states_per_gauge/all_gauges_states.npz')\n",
        "h_n = states['h_n']  # (n_gauges, n_timesteps, hidden_size)\n",
        "c_n = states['c_n']  # (n_gauges, n_timesteps, hidden_size)\n",
        "gauge_ids = states['gauge_ids']\n",
        "\n",
        "# Get states for specific gauge\n",
        "gauge_idx = np.where(gauge_ids == '12345')[0][0]\n",
        "gauge_h_states = h_n[gauge_idx]  # (n_timesteps, hidden_size)\n",
        "```\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "next_steps",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "After running this notebook, you'll have per-gauge LSTM states that can be properly analyzed:\n",
        "\n",
        "1. **Update `c3_LSTMStates_v2.ipynb`** to load from `all_gauges_states.npz`\n",
        "2. **Per-gauge correlation**: Correlate each gauge's state trajectory with its own meteo data\n",
        "3. **Cluster analysis**: Group gauges by which cells dominate, compare to hybrid clusters\n",
        "4. **h_n vs c_n comparison**: Now valid since states are gauge-specific\n",
        "\n",
        "The key difference from before:\n",
        "- **Before**: One state trajectory correlated with 996 different gauges' meteo\n",
        "- **Now**: Each gauge's state trajectory correlated with its own meteo"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
